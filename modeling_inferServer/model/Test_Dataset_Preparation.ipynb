{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VJaXbnaVRnH",
        "outputId": "84306f21-45e5-4975-806c-fff6fd076030"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[106], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[39m.\u001b[39mmount(\u001b[39m'\u001b[39m\u001b[39m/content/drive\u001b[39m\u001b[39m'\u001b[39m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "56c6Ezq-WPGA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pywt\n",
        "import pandas as pd\n",
        "import pickle as pkl\n",
        "from matplotlib import pyplot as plt\n",
        "import platform\n",
        "import glob\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ng6JFHqVXUUD"
      },
      "source": [
        "#변수 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "b6rTaEbnW79T"
      },
      "outputs": [],
      "source": [
        "DATA_POINTS_PER_FILE = 2560\n",
        "TIME_PER_REC = 0.1\n",
        "SAMPLING_FREQ = 25600 # 25.6 KHz\n",
        "SAMPLING_PERIOD = 1.0/SAMPLING_FREQ\n",
        "\n",
        "WIN_SIZE = 20\n",
        "WAVELET_TYPE = 'morl'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#CWT 변환\n",
        "    (1). pkz파일 불러오기\n",
        "    (2). 데이터 길이 맞춰주기\n",
        "    (3). 연속 웨이블릿 변환(CWT) 실행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8uAGL6_AXcL6"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_df(pkz_file):\n",
        "    with open(pkz_file, 'rb') as f:\n",
        "        df=pkl.load(f)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WH73xogWYi8F"
      },
      "outputs": [],
      "source": [
        "def df_row_ind_to_data_range(ind):\n",
        "    retnd, DATA_POINTSurn (DATA_POINTS_PER_FILE*i_PER_FILE*(ind+1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aAwZ2ieDY05e"
      },
      "outputs": [],
      "source": [
        "\n",
        "def extract_feature_image(ind, feature_name='horiz accel'):\n",
        "    data_range = df_row_ind_to_data_range(ind)\n",
        "    data = df[feature_name].values[data_range[0]:data_range[1]]\n",
        "\n",
        "    data = np.array([np.mean(data[i:i+WIN_SIZE]) for i in range(0, DATA_POINTS_PER_FILE, WIN_SIZE)])  \n",
        "\n",
        "    coef, _ = pywt.cwt(data, np.linspace(1,128,128), WAVELET_TYPE)  \n",
        "\n",
        "    coef = np.log2(coef**2+0.001) \n",
        "\n",
        "    coef = (coef - coef.min())/(coef.max() - coef.min()) \n",
        "    return coef"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miYW3ZwvgErc"
      },
      "source": [
        "## 메인 디렉토리 경로 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "fKH8lB_ic7uW"
      },
      "outputs": [],
      "source": [
        "## root project에서 model 경로에서 실행한다고 가정되어 있음 \n",
        "\n",
        "def get_root_project_dir():\n",
        "    \"\"\"Get the root project directory.\"\"\"\n",
        "    if platform.system() == 'Windows':\n",
        "        return os.path.normpath(os.path.join(os.getcwd(), '..')) \n",
        "    else:\n",
        "        return os.path.normpath(os.path.join(os.getcwd(), '..'))\n",
        "\n",
        "main_dir = get_root_project_dir()\n",
        "setting = '/data/Learning_set/' ## /Test_set/ /Learning_set/  중 하나 사용\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/home/i4624/vscode/gitclone/org/learning_infer/data/Learning_set/'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dir = main_dir + setting\n",
        "dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7cWr0Yxgvif"
      },
      "source": [
        "## Bearing Loading "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "y1dqa2axciCH",
        "outputId": "88c22044-8f50-4205-c531-8dd2f3406451"
      },
      "outputs": [],
      "source": [
        "def bearing_load(dir, pkz_file):\n",
        "    path = dir+'/'+pkz_file\n",
        "    df=load_df(path)\n",
        "    df.head()\n",
        "    no_of_rows = df.shape[0]\n",
        "    no_of_files = int(no_of_rows / DATA_POINTS_PER_FILE)\n",
        "    print(no_of_rows, no_of_files)\n",
        "    return df, no_of_rows, no_of_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_file_list(pattern, directory):\n",
        "    file_list = glob.glob(f'{directory}/{pattern}')\n",
        "    filtered_file_list = [os.path.basename(file) for file in file_list if re.search(r'Bearing\\d+_\\d+_noise\\.pkz$', file)]\n",
        "    #### 위의 패턴과 동일하게 적어야 함 \n",
        "    return filtered_file_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Bearing1_1_noise.pkz', 'Bearing1_2_noise.pkz']\n"
          ]
        }
      ],
      "source": [
        "## 패턴은 피클즈 파일 이름 앞 부분이 서로 일치하게 되어야 합니다.\n",
        "pattern = 'Bearing*_*_*.pkz'\n",
        "file_list = get_file_list(pattern, dir)\n",
        "file_list = sorted(file_list)\n",
        "print(file_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGQdZhE2hhkQ",
        "outputId": "81e35b67-1148-4006-d847-96250f810650"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6080000 2375\n",
            "Processed Bearing1_3_noise.pkz: Rows=6080000, Files=2375\n",
            "3655680 1428\n",
            "Processed Bearing1_4_noise.pkz: Rows=3655680, Files=1428\n",
            "6305280 2463\n",
            "Processed Bearing1_5_noise.pkz: Rows=6305280, Files=2463\n",
            "6266880 2448\n",
            "Processed Bearing1_6_noise.pkz: Rows=6266880, Files=2448\n",
            "5783040 2259\n",
            "Processed Bearing1_7_noise.pkz: Rows=5783040, Files=2259\n"
          ]
        }
      ],
      "source": [
        "dataframes_info = {}  # Dictionary to store dataframe information\n",
        "\n",
        "for file in file_list:\n",
        "    df, no_of_rows, no_of_files = bearing_load(dir, file)\n",
        "    filename = os.path.basename(file)  # Extract filename without path\n",
        "    dataframes_info[filename] = (df, no_of_rows, no_of_files)\n",
        "    print(f\"Processed {filename}: Rows={no_of_rows}, Files={no_of_files}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting 1D vibration signals(그래프로 그리기) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_acceleration(df, filename, no_of_rows):\n",
        "    # Create a plot for horizontal acceleration\n",
        "    plt.plot(range(no_of_rows), df['horiz accel'])\n",
        "    plt.title(f'Horizontal Acceleration - {filename}')\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Acceleration')\n",
        "    plt.show()\n",
        "\n",
        "    # Create a plot for vertical acceleration\n",
        "    plt.plot(range(no_of_rows), df['vert accel'], 'r')\n",
        "    plt.title(f'Vertical Acceleration - {filename}')\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Acceleration')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Now you can access dataframe information using dataframes_info dictionary\n",
        "for filename, (df, no_of_rows, no_of_files) in dataframes_info.items():\n",
        "    print(f\"Filename: {filename}, Rows: {no_of_rows}, Files: {no_of_files}\")\n",
        "    print(df.head())\n",
        "    # Call the plot function for the current dataframe\n",
        "    plot_acceleration(df, filename, no_of_rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfLun1tLmbVO"
      },
      "source": [
        "**(1)신호처리 - 시간, 주파수 영역 특성 이미지 추출**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "X_DE_Y_FjPI1",
        "outputId": "3080acd3-960a-4acd-f310-76fc3742270f"
      },
      "outputs": [],
      "source": [
        "def plot_feature_images(ind, no_of_samples=5, no_of_files=None):\n",
        "    fig, ax = plt.subplots(2, no_of_samples, figsize=[20, 8])\n",
        "    ax[0, 0].set_ylabel('horiz accel features image')\n",
        "    ax[1, 0].set_ylabel('vert accel features image')\n",
        "\n",
        "    for i, p in enumerate(np.linspace(0, 1, no_of_samples)):\n",
        "        current_ind = int((no_of_files - 1) * p)\n",
        "\n",
        "        for j, feature_name in enumerate(['horiz accel', 'vert accel']):\n",
        "            coef = extract_feature_image(ind[current_ind], feature_name=feature_name)\n",
        "            ax[j, i].set_title('{0:.2f}'.format(p))\n",
        "            im = ax[j, i].imshow(coef, cmap='coolwarm')\n",
        "            fig.colorbar(im, ax=ax[j, i], fraction=0.046, pad=0.04)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loop through the dataframes_info dictionary\n",
        "for filename, (df, no_of_rows, no_of_files) in dataframes_info.items():\n",
        "    print(f\"Filename: {filename}, Rows: {no_of_rows}, Files: {no_of_files}\")\n",
        "    print(df.head())\n",
        "    \n",
        "    # Create an array of indices\n",
        "    indices = np.arange(no_of_files)\n",
        "    \n",
        "    # Call the feature function for the current dataframe\n",
        "    plot_feature_images(indices, no_of_samples=5, no_of_files=no_of_files)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##timestamp 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bearing1_1_noise.pkz: 2557 files processed, x_ shape: (2557, 2, 128, 128)\n",
            "Processed data saved to /home/i4624/vscode/gitclone/org/learning_infer/data/Learning_set/Bearing1_1_noise_test_data_timestamp.pkz\n",
            "Bearing1_2_noise.pkz: 871 files processed, x_ shape: (871, 2, 128, 128)\n",
            "Processed data saved to /home/i4624/vscode/gitclone/org/learning_infer/data/Learning_set/Bearing1_2_noise_test_data_timestamp.pkz\n"
          ]
        }
      ],
      "source": [
        "for filename in file_list:  # Assuming file_list contains your list of filenames\n",
        "    # Load the dataframe from the file\n",
        "    df = load_df(os.path.join(dir, filename))\n",
        "    no_of_files = int(df.shape[0] / DATA_POINTS_PER_FILE)\n",
        "    \n",
        "    data = {'timestamps': [], 'x': []}  # Initialize data inside the loop\n",
        "\n",
        "    for i in range(0, no_of_files):\n",
        "        coef_h = extract_feature_image(i,  feature_name='horiz accel')\n",
        "        coef_v = extract_feature_image(i,  feature_name='vert accel')\n",
        "        x_ = np.array([coef_h, coef_v])\n",
        "        data['x'].append(x_)\n",
        "\n",
        "        # Create a datetime object with only time information\n",
        "        idx = i * DATA_POINTS_PER_FILE\n",
        "        timestamp = datetime.datetime.min.time().replace(hour=df.iloc[idx, 0], minute=df.iloc[idx, 1], second=df.iloc[idx, 2])\n",
        "        data['timestamps'].append(timestamp)\n",
        "\n",
        "    data['x'] = np.array(data['x'])\n",
        "\n",
        "    assert data['x'].shape == (no_of_files, 2, 128, 128)\n",
        "    print(f\"{filename}: {no_of_files} files processed, x_ shape: {data['x'].shape}\")\n",
        "\n",
        "    # Generate the output filename with \"_timestamp\" suffix\n",
        "    base_filename = os.path.splitext(filename)[0]\n",
        "    out_filename = base_filename + '_test_data_timestamp.pkz'\n",
        "    out_path = os.path.join(dir, out_filename)\n",
        "\n",
        "    # Save the processed data with timestamp\n",
        "    with open(out_path, 'wb') as f:\n",
        "        pkl.dump(data, f)\n",
        "\n",
        "    print(f\"Processed data saved to {out_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/home/i4624/vscode/gitclone/org/learning_infer/data/Test_set/'"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dir"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Test_Dataset_Preparation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
